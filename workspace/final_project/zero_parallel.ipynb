{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b55fc5f-e5ab-4d61-abaf-2dfae68bcb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from loaders import *\n",
    "from workloads import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a02b1fe7-c51a-4bab-9cf3-53876be8bb42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ========================================================================\n",
      "# Please do not modify this file. If there are double-curly-brace-enclosed\n",
      "# statements, they are placeholders that should be set from the notebooks.\n",
      "# ========================================================================\n",
      "architecture:\n",
      "  version: 0.4\n",
      "  nodes:\n",
      "  - !Container\n",
      "    name: data_parallel_arch\n",
      "    attributes:\n",
      "      # Top-level attributes inherited by all components unless overridden\n",
      "      technology: \"45nm\"\n",
      "      global_cycle_seconds: 1e-9\n",
      "      datawidth: 16\n",
      "\n",
      "  - !Component\n",
      "    name: disk                 # disk is the source of all datatypes\n",
      "    class: DRAM                \n",
      "    attributes:\n",
      "      width: 64                # width in bits\n",
      "      datawidth: datawidth \n",
      "      depth: 999999\n",
      "\n",
      "  - !Container\n",
      "    name: GPU\n",
      "    spatial: {meshX: {{gpu_meshX}}, meshY: {{gpu_meshY}}}\n",
      "    \n",
      "  - !Component\n",
      "    name: self_memory\n",
      "    class: SRAM\n",
      "    attributes:\n",
      "      width: 128\n",
      "      depth: 999999\n",
      "      datawidth: datawidth\n",
      "      n_banks: 1\n",
      "      n_rdwr_ports: 2\n",
      "\n",
      "  - !Container\n",
      "    name: PE\n",
      "    spatial: {meshX: {{pe_meshX}}, meshY: {{pe_meshY}}}\n",
      "\n",
      "  - !Component\n",
      "    name: scratchpad\n",
      "    class: smart_storage  # definitions of the compound classes can be found under \"components\" folder\n",
      "    attributes: {depth: 128, width: 16, datawidth: datawidth}\n",
      "\n",
      "  - !Component\n",
      "    name: weight_reg\n",
      "    class: reg_storage\n",
      "    attributes: {depth: 1, width: 16, datawidth: datawidth}\n",
      "      \n",
      "  - !Component\n",
      "    name: input_activation_reg\n",
      "    class: reg_storage\n",
      "    attributes: {depth: 1, width: 16, datawidth: datawidth}\n",
      "\n",
      "  - !Component\n",
      "    name: output_activation_reg\n",
      "    class: reg_storage\n",
      "    attributes: {depth: 1, width: 16, datawidth: datawidth}\n",
      "\n",
      "  - !Component\n",
      "    name: mac\n",
      "    class: mac_compute\n",
      "    attributes: {num_pipline_stages: 2, datawidth: datawidth}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_config('designs/data_parallel/arch.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3f1770-cfc9-43cf-9e0e-59706fb4ecd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ========================================================================\n",
      "# Please do not modify this file. If there are double-curly-brace-enclosed\n",
      "# statements, they are placeholders that should be set from the notebooks.\n",
      "# ========================================================================\n",
      "mapping:\n",
      "- target: disk\n",
      "  type: temporal\n",
      "  factors: \n",
      "  - P=1\n",
      "  - Q=1\n",
      "  - R=1\n",
      "  - S=1\n",
      "  - N={{disk_factor_N}}\n",
      "  - M={{disk_factor_M}}\n",
      "  - C={{disk_factor_C}}\n",
      "  permutation: [S, R, Q, P, C, M, N] # don't change this\n",
      "\n",
      "- target: GPU\n",
      "  type: spatial  # spatial constraint specification\n",
      "  factors: \n",
      "  - P=1\n",
      "  - Q=1\n",
      "  - R=1\n",
      "  - S=1\n",
      "  - N={{GPU_spatial_factor_N}}\n",
      "  - M={{GPU_spatial_factor_M}}\n",
      "  - C={{GPU_spatial_factor_C}}\n",
      "  permutation: [N, C, M, R, S, P, Q]\n",
      "  # tells at which index should the dimensions be mapped to Y (GPU cols),\n",
      "  # the dimensions before that index all should map to X (GPU rows)\n",
      "  split: 1\n",
      "  \n",
      "- target: self_memory\n",
      "  type: temporal\n",
      "  factors: \n",
      "  - P=1\n",
      "  - Q=1\n",
      "  - R=1\n",
      "  - S=1\n",
      "  - N={{self_memory_factor_N}}\n",
      "  - M={{self_memory_factor_M}}\n",
      "  - C={{self_memory_factor_C}}\n",
      "  permutation: [S, R, Q, P, C, M, N] # don't change this\n",
      "\n",
      "- target: PE\n",
      "  type: spatial  # spatial constraint specification\n",
      "  factors: \n",
      "  - P=1\n",
      "  - Q=1\n",
      "  - R=1\n",
      "  - S=1\n",
      "  - N=1\n",
      "  - M={{PE_spatial_factor_M}}\n",
      "  - C={{PE_spatial_factor_C}}\n",
      "  permutation: [C, M, R, S, P, Q, N]\n",
      "  # tells at which index should the dimensions be mapped to Y (PE cols),\n",
      "  # the dimensions before that index all should map to X (PE rows)\n",
      "  split: 1\n",
      "\n",
      "- target: scratchpad\n",
      "  type: temporal\n",
      "  factors: \n",
      "  - R=0\n",
      "  - S=0\n",
      "  - P=0\n",
      "  - Q=0\n",
      "  - M=1\n",
      "  - C=1\n",
      "  - N={{scratchpad_factor_N}}\n",
      "  permutation: [Q, P, N, C, M, S, R]\n",
      "\n",
      "- target: scratchpad\n",
      "  type: dataspace\n",
      "  keep: [Weights]\n",
      "  bypass: [Inputs, Outputs]\n",
      "\n",
      "- target: weight_reg\n",
      "  type: dataspace\n",
      "  keep: [Weights]\n",
      "  bypass: [Inputs, Outputs]\n",
      "- target: weight_reg\n",
      "  type: temporal\n",
      "  factors: [R=1, S=1, P=1, Q=1, N=1, C=1, M=1]\n",
      "  permutation: [R, S, P, Q, C, M, N]\n",
      "- target: input_activation_reg\n",
      "  type: dataspace\n",
      "  keep: [Inputs]\n",
      "  bypass: [Weights, Outputs]\n",
      "- target: input_activation_reg\n",
      "  type: temporal\n",
      "  factors: [R=1, S=1, P=1, Q=1, N=1, C=1, M=1]\n",
      "  permutation: [R, S, P, Q, C, M, N]\n",
      "- target: output_activation_reg\n",
      "  type: dataspace\n",
      "  keep: [Outputs]\n",
      "  bypass: [Weights, Inputs]\n",
      "- target: output_activation_reg\n",
      "  type: temporal\n",
      "  factors: [R=1, S=1, P=1, Q=1, N=1, C=1, M=1]\n",
      "  permutation: [R, S, P, Q, C, M, N]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_config('designs/data_parallel/map.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13f31c51-4ce0-4a5a-8edc-a7c73a0d78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCH_CONFIG = dict(\n",
    "    gpu_meshX=1,\n",
    "    gpu_meshY=1,\n",
    "    pe_meshX=4, \n",
    "    pe_meshY=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbc9d0b5-e1dc-425a-b23b-884de6794a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2025-04-15 06:06:21,995 - pytimeloop.accelergy_interface - Running Accelergy with command: accelergy /home/workspace/final_project/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytimeloop.accelergy_interface:Running Accelergy with command: accelergy /home/workspace/final_project/output_dir/parsed-processed-input.yaml -o ./output_dir/ -v\n"
     ]
    }
   ],
   "source": [
    "config = dict( # Do not change this configuration!\n",
    "    disk_factor_N=1,\n",
    "    disk_factor_M=1,\n",
    "    disk_factor_C=1,\n",
    "    other_memories_factor_N=1,\n",
    "    other_memories_factor_M=1,\n",
    "    other_memories_factor_C=1,\n",
    "    GPU_spatial_factor_M=1,\n",
    "    GPU_spatial_factor_C=1,\n",
    "    GPU_spatial_factor_N=1,\n",
    "    self_memory_factor_N=1,\n",
    "    self_memory_factor_M=2,\n",
    "    self_memory_factor_C=1,\n",
    "    PE_spatial_factor_M=4,\n",
    "    PE_spatial_factor_C=4,\n",
    "    scratchpad_factor_N=1,\n",
    ")\n",
    "\n",
    "full_config = {\n",
    "    **config,\n",
    "    **ARCH_CONFIG,\n",
    "    **conv2,\n",
    "    'batch_size': 1, # overwrite conv2 batch_size\n",
    "}\n",
    "\n",
    "result = run_timeloop_model(\n",
    "    full_config,\n",
    "    architecture='designs/data_parallel/arch.yaml',\n",
    "    mapping='designs/data_parallel/map.yaml',\n",
    "    problem='layer_shapes/workload.yaml'\n",
    ")\n",
    "stats = open('./output_dir/timeloop-model.stats.txt', 'r').read()\n",
    "mapping = result.mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb55ce75-b85c-4d59-b2d0-87874bb35b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disk [ Weights:800 (800) Inputs:4096 (4096) Outputs:6272 (6272) ] \n",
      "self_memory [ Weights:800 (800) Inputs:4096 (4096) Outputs:6272 (6272) ] \n",
      "------------------------------------------------------------------------\n",
      "| for M in [0:2)\n",
      "\n",
      "inter_PE_spatial [ ] \n",
      "--------------------\n",
      "|   for M in [0:4) (Spatial-Y)\n",
      "|     for C in [0:4) (Spatial-X)\n",
      "\n",
      "scratchpad [ Weights:25 (25) ] \n",
      "------------------------------\n",
      "|       for R in [0:5)\n",
      "|         for S in [0:5)\n",
      "|           for P in [0:28)\n",
      "|             for Q in [0:28)\n",
      "\n",
      "weight_reg [ Weights:1 (1) ] \n",
      "input_activation_reg [ Inputs:1 (1) ] \n",
      "output_activation_reg [ Outputs:1 (1) ] \n",
      "---------------------------------------\n",
      "|               << Compute >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "294152e7-2251-4dd2-bc78-5ffbdf149be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energy(result, workload):\n",
    "    access_energy_factor = 1e-9 # Change this\n",
    "    return workload['batch_size'] * (result.energy - result.per_component_energy['disk']) \\\n",
    "        + (workload['batch_size'] - 1) * get_weight_size(workload) * access_energy_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8affd3e-99d1-4424-b40e-ab30791242f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latency(result, workload):\n",
    "    access_latency_factor = 1e-9 # Change this\n",
    "    return result.latency \\\n",
    "        + ((workload['batch_size'] - 1) / workload['batch_size']) * get_weight_size(workload) * access_latency_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82e16e9d-f183-4c6c-9db4-960e27ade7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000584933953536"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_energy(result, conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73c252b2-94ba-4ff8-b886-49258e5a48e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.995e-05"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_latency(result, conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa06407-4873-417b-a289-16bb47f52f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
